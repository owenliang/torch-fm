{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad496a",
   "metadata": {},
   "source": [
    "数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Lambda(lambda x:2*x-1),\n",
    "])\n",
    "dataset=torchvision.datasets.mnist.MNIST(root='./data',train=True,download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img,label=dataset[0]\n",
    "print(f'img={img.shape} label={label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1fe94f",
   "metadata": {},
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSample(torch.nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,condition_size):\n",
    "        super().__init__()\n",
    "        self.downconv=torch.nn.Sequential( \n",
    "            torch.nn.Conv2d(in_channels=in_channels+condition_size,out_channels=out_channels,kernel_size=3,padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=out_channels,out_channels=out_channels,kernel_size=3,padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.maxpool=torch.nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "    def add_condition(self,tensor,cond_emb):\n",
    "        cond_emb=cond_emb.view(cond_emb.size(0),cond_emb.size(1),1,1)\n",
    "        return torch.concat([tensor,cond_emb.expand(-1,-1,tensor.size(2),tensor.size(3))],dim=1)\n",
    "    \n",
    "    def forward(self,x,condition):\n",
    "        x=self.downconv(self.add_condition(x,condition))\n",
    "        return x,self.maxpool(x)\n",
    "\n",
    "class UpSample(torch.nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,condition_size):\n",
    "        super().__init__()\n",
    "        self.deconv=torch.nn.Sequential( \n",
    "            torch.nn.ConvTranspose2d(in_channels=in_channels+condition_size,out_channels=out_channels,kernel_size=4,stride=2,padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.upconv=torch.nn.Sequential( \n",
    "            torch.nn.Conv2d(in_channels=in_channels+condition_size,out_channels=out_channels,kernel_size=3,padding=1),\n",
    "            torch.nn.ReLU(),            \n",
    "            torch.nn.Conv2d(in_channels=out_channels,out_channels=out_channels,kernel_size=3,padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def add_condition(self,tensor,cond_emb):\n",
    "        cond_emb=cond_emb.view(cond_emb.size(0),cond_emb.size(1),1,1)\n",
    "        return torch.concat([tensor,cond_emb.expand(-1,-1,tensor.size(2),tensor.size(3))],dim=1)\n",
    "    \n",
    "    def forward(self,x,redidual_x,condition):\n",
    "        x=self.deconv(self.add_condition(x,condition))\n",
    "        x=torch.concat([x,redidual_x],dim=1)\n",
    "        x=self.upconv(self.add_condition(x,condition))\n",
    "        return x\n",
    "\n",
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet,self).__init__()\n",
    "        \n",
    "        # condition\n",
    "        self.label_emb=torch.nn.Embedding(num_embeddings=10,embedding_dim=16)\n",
    "        self.t_emb=torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=1,out_features=32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=32,out_features=16),\n",
    "        )\n",
    "        self.condition_size=32\n",
    "\n",
    "        self.down0=DownSample(in_channels=1,out_channels=64,condition_size=self.condition_size)\n",
    "        self.down1=DownSample(in_channels=64,out_channels=128,condition_size=self.condition_size)\n",
    "        self.down2=DownSample(in_channels=128,out_channels=256,condition_size=self.condition_size)\n",
    "        \n",
    "        self.up0=UpSample(in_channels=256,out_channels=128,condition_size=self.condition_size)\n",
    "        self.up1=UpSample(in_channels=128,out_channels=64,condition_size=self.condition_size)\n",
    "        \n",
    "        self.output_conv=torch.nn.Conv2d(in_channels=64+self.condition_size,out_channels=1,kernel_size=3,padding=1)\n",
    "    \n",
    "    def add_condition(self,tensor,cond_emb):\n",
    "        cond_emb=cond_emb.view(cond_emb.size(0),cond_emb.size(1),1,1)\n",
    "        return torch.concat([tensor,cond_emb.expand(-1,-1,tensor.size(2),tensor.size(3))],dim=1)\n",
    "    \n",
    "    def forward(self,x,t,label):\n",
    "        cond_emb=torch.concat((self.label_emb(label),self.t_emb(t.unsqueeze(1))),dim=1)\n",
    "        \n",
    "        x0,x=self.down0(x,cond_emb) # torch.Size([128, 64, 28, 28]) torch.Size([128, 64, 14, 14])\n",
    "        x1,x=self.down1(x,cond_emb) # torch.Size([128, 128, 28, 28]) torch.Size([128, 128, 14, 14])\n",
    "        x,_=self.down2(x,cond_emb)  # torch.Size([128, 256, 7, 7])\n",
    "        x=self.up0(x,x1,cond_emb)   # torch.Size([128, 128, 14, 14])\n",
    "        x=self.up1(x,x0,cond_emb)   # torch.Size([128, 64, 28, 28])\n",
    "        return self.output_conv(self.add_condition(x,cond_emb)) # torch.Size([128, 1, 28, 28])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a155b438",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50677fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=UNet().to(device)\n",
    "dataloader=torch.utils.data.DataLoader(dataset,batch_size=128,shuffle=True)\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f99c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "model.train()\n",
    "while True:\n",
    "    for batch_img,batch_labels in dataloader:\n",
    "        batch_img=batch_img.to(device)\n",
    "        batch_labels=batch_labels.to(device)\n",
    "        \n",
    "        batch_t=torch.rand(size=(batch_img.size(0),)).to(device)\n",
    "        batch_noise=torch.randn_like(batch_img).to(device)\n",
    "        batch_xt=(1-batch_t.view(-1,1,1,1))*batch_noise+batch_t.view(-1,1,1,1)*batch_img\n",
    "        \n",
    "        # flow matching model\n",
    "        pred_vt=model(batch_xt,batch_t,batch_labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss=torch.nn.functional.mse_loss(pred_vt,batch_img-batch_noise)\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "    torch.save(model.state_dict(),'.model.pt')\n",
    "    os.replace('.model.pt','model.pt')\n",
    "    print(f'loss={loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4748e7",
   "metadata": {},
   "source": [
    "推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68097f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=torch.randn(size=(1,1,28,28)).to(device)\n",
    "steps=250\n",
    "label=5\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(steps):\n",
    "        t=torch.tensor([1.0/steps*i]).to(device)\n",
    "        label=torch.tensor([label],dtype=torch.long).to(device)\n",
    "        pred_vt=model(x,t,label)\n",
    "        x=x+pred_vt*1.0/steps\n",
    "        x=x.detach()\n",
    "    \n",
    "x=(x+1)/2\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.axis('off')\n",
    "plt.imshow(x[0,0].cpu().numpy(),cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
